%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.

\documentclass[sigconf]{acmart}
\usepackage{multirow}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2019}
\acmYear{2019}
\acmDOI{10.1145/1122445.1122456}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Summer '19]{Summer '19: A Summer Research Internship on Database}{Jun. 11--Sept. 10, 2019}{Singapore, SG}
\acmBooktitle{Summer '19: A Summer Research Internship on Database,
  Jun. 11--Sept. 10, 2019, Singapore, SG}
\acmPrice{15.00}
\acmISBN{978-1-4503-9999-9/18/06}



\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Vision Trajectory Database}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.



%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\author{Tiger Hou}
\affiliation{%
	\institution{Peking University}
	\city{Beijing}
	\country{China} 
}
\email{houtiger@pku.edu.cn}

\author{Sheng Wang}
\affiliation{%
	\institution{New York University}
	\state{NY}
	\country{USA}
}
\email{swang@nyu.edu}



\begin{abstract}
This paper is a survey on visual trajectory, which is defined as trajectory extracted from visual objects like video and image. We will introduce the application scenes of visual trajectory and point out the limitation of previous works. And then, we will explain why it's essential to build a trajectory database for these tasks and show some new tasks can be supplied by such a database. Challenges of normalization and similarity measurement would be discussed. Available datasets would also be presented in the end.  
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
	<ccs2012>
	<concept>
	<concept_id>10002951.10002952.10002953</concept_id>
	<concept_desc>Information systems~Database design and models</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Database design and models}

\keywords{database management, handwriting trajectory, drawing trajectory}

\maketitle

\section{Introduction}
%% In introduction, we state the possible application background and motivation of our paper. And briefly summarize the mothod we proposed.
Nowadays, many works focus on vehicle trajectory management have been proposed. However, for another series of trajectory, like handwriting trajectory and drawing trajectory, which we call \textit{visual trajectory}, they haven't been fully studied. There are four main differences between visual and vehicle trajectory: 1) Freely distributed, unlike vehicles are constrained to road network, handwriting and drawing trajectory exists everywhere on the 2D ground. So the traditional map matching method \cite{Wang2018} cannot be applied to this new problem; 2) Accurately recorded, vehicles trajectory recording relies on unstable GPS accuracy, but for visual trajectory, it is recorded by human-machine interaction equipment accurately \cite{VikramLR13}, which makes it easier for similarity search; 3) Same simple rates, due to the same pen-based recording devices; 4) Dense and frequently crossing, visual trajectory extracted from image or video is restrained to the fixed image size, and there are a lot of crossing between trajectories, which means we can not treat it as a set matching problem in similarity search but have to consider temporal order information. 

So, we would like to propose a visual trajectory database which supports both whole trajectory and sub-trajectory Top-k similarity search, with a balanced efficiency and effectiveness, e.g. the high similarity search accuracy and retrieval speed. 

The possible application scenes include: 

\noindent
\textbf{1) Handwriting recognition and user identification}. As a classic problem, handwriting user identification and recognition has been well studied in computer vision area \cite{WangL17}. While in handwriting user identification, lack of training data has always been a tough issue for Convolutional Neural Network (CNN) training. But if a handwriting trajectory search database was built, it would solve this problem easily because it can work well even in one-shot condition, which means we only have gotten one sample for each handwritten character of a certain user. For character recognition, the idea that visually similar handwriting characters can be distinguished by writing trajectories has been commonly accepted, as Geoffrey E. Hinton mentioned in \cite{HintonN05}. And trajectory reconstruction methods based on combination of CNN and RNN or Generative Adversarial Network (GAN) have been mature enough \cite{ICPRtraj, GuptaJFSA18}. So when it comes to a messy classification problem that two handwritten characters are visually similar, our database can provide essential help in trajectory similarity search for recognition, on condition that trajectories have been reconstructed. 

\noindent
\textbf{2) Drawing recommendation}. Sketch-based image retrieval has been a hot topic for a long time \cite{SangkloyBHH16}. It is more convenient for users to describe features of their target in drawings than natural language.  But the current vector embedding search method doesn't support sub-trajectory search, because it's hard to map whole trajectory and sub-trajectory into the same space while ensure high similarity between them. If this operation is supported, the searching expense can be largely reduced by a simple click of the target category. 

\noindent
\textbf{3) Sports play retrieval}. Sports play retrieval by trajectory searching have been studied in \cite{DBLP:conf/kdd/WangLCJ19, iui/ShaLYCRM16}. But the current solution is usually embedding trajectories into vectors in a space, and measure the distance through cosine similarity, which means the previous methods do not support sub-trajectory search, either.

\noindent
\textbf{4) Human-computer interaction}. At the moment, a lot of human computer interaction methods are based on finger moving trajectory similarity search \cite{VikramLR13}. But the searching is too time consuming, an enumerate DTW-based trajectory similarity search in a dataset with 160 trajectories would take roughly 10 seconds, which is so time-consuming. A visual trajectory database support efficient retrieval would surely be useful in this task.  

\section{Related Work}
%% we summarize the related work, but don't need to compare with our method.
\noindent
\textbf{Trajectory Reconstruction from Videos and Images.} 
Reconstructing trajectory from image and video has been a fully studied problem in computer vision area, like handwriting character trajectory, drawing trajectory and pedestrian motion. Usually, a combination of Convolution Neural Network (CNN) and Recursive Neural Network (RNN) is preferred for image trajectory reconstruction \cite{ICPRtraj}. And there are also works focus on feature designing and computing \cite{CVPR/videotrackds}. When it comes to video trajectory, Generative Adversarial Network (GAN) is applied in these tasks \cite{GuptaJFSA18}. 

\noindent
\textbf{Trajectory Similarity Measures.} In measuring trajectory similarity, Dynamic Time Warping (DTW) is a well accepted method. Different from Euclidean Distance, DTW consider matching points within a certain time window, that's also how the name ``warping'' comes. But the expense of computation is very large, and several optimizations are proposed in \cite{RakthanmanonDTW, vldb/LB_keogh, KeoghWXVLP09}, including lower bound pruning, early abandoning Z-Normalization, reordering early abandoning, reversing the Query/Document role in $LB_{keogh}$ and cascading lower bounds. Besides, Longest Common Subsequence (LCSS) and Edit Distance on Real Sequence (EDRS) are also widely accepted trajectory similarity measures. Even though, the approximate computing complexity of current popular measures is still $O(mn)$, where $m$ and $n$ represent the length of query and candidate sequences separately. 

\section{Challenge}
%% what is the key difficulty in this
\subsection{Preprocessing of Trajectories}
We separate the preprocessing of trajectory into two problems: resizing and normalization. For example, the length of trajectory extracted from a $1000 \times 1000$ image and a $25 \times 25$ image would be definitely different. And the coordinates of points that consist the trajectory would also be changing if the handwritten character is moved from lower right corner to upper left corner of the image. Image resizing has been a fully studied problem in computer vision area \cite{CVPR/imageresize}. And resizing character into our desired size is an easy job. And for image normalization, many methods have been proposed for medical image normalization \cite{isbi/OnofreyCLSVFSSS19}, which is also applicable to our problem. 
\subsection{Support Sub-trajectory  Search}
As we are supporting sub-trajectory search, then the vector embedding method is not applicable. The distance between whole trajectory and sub-trajectory in the mapped space is very large as the vector only posses general feature, while neglecting local feature at the same time. So we have to implement the sub-trajectory search based on the time sequence similarity measurements like DTW or curve similarity measurements like Hausdorff distance and Fr√©chet distance \cite{siam/AgarwalAKS14,pvldb/NutanongJS11}.
\subsection{Similarity Measures}
The similarity measurement determines the efficiency of our database directly. Although measures like Dynamic TIme Warping (DTW), Longest Common Subsequence (LCSS), and Edit Distance on Real sequence (EDR) are robust to local time shifting and noise, but they all require a lot of computations with $O(n^2)$ complexity. In our task, the size of trajectory dataset usually ranges between no less than 1 million and 50 million, which means we have to figure out how to reduce the computations and in the mean while, ensure accuracy. 
 

\section{Datasets}
There are datasets of vision trajectories of considerable size. For handwriting characters, the CASIA database of Chinese character handwriting trajectories \cite{DBLP:conf/icdar/LiuYWW11} consists of over 1.6 million trajectories of more than 3000 classes. And trajectory databases of other languages are also available, like English \cite{UJIPen}, Japanese \cite{icdar/Japanese} and Vietnamese \cite{Vietnamese}, etc. We show the statistics of CASIA database in \textbf{Table 1}. 
\begin{table}
	\caption{Statistics of CASIA Database}
	\label{tab:CASIA}
	\begin{tabular}{|l|l|l|l|l|}
		\hline
		\multirow{2}{*}{dataset} & \multirow{2}*{writers} & \multicolumn{3}{|c|}{character samples} \\
		\cline{3-5}
		& & total & symbol & Chinese/class \\ 
		\hline
		OLHWDB1.0 & 420 & 1,694,741 & 71,806 & 1,622,935/3,866 \\
		\hline
		OLHWDB1.1 & 300 & 1,174,364 & 51,232 & 1,123,132/3,755 \\
		\hline
		OLHWDB1.2 & 300 & 1,042,912 & 51,181 & 991,731/3,319 \\
		\hline
		total & 1,020 & 3,912,017 & 174,219 & 3,737,798/7,185\\
		\hline
	
	\end{tabular}
\end{table}

Besides, a drawing trajectory dataset \cite{Quickdraw} is provided by Google, which contains 50 million drawings across 345 categories. Another drawing trajectory dataset is provided by Georgia Institute of Technology \cite{SangkloyBHH16} with over 7000 trajectories. In the Georgia Tech dataset, each sketch drawing is labeled with an original image, from which it was generated.

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}






\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
